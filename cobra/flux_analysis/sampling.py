"""Module implementing flux sampling for cobra models.

New samplers should derive from the abstract `HRSampler` class
where possible to provide a uniform interface.
"""

import numpy as np
from ..solvers import solver_dict, get_solver_name
from copy import deepcopy
from builtins import range

BTOL = np.finfo(np.float32).eps
"""The tolerance used for checking bounds feasibility."""

FTOL = BTOL
"""The tolerance used for checking equalities feasibility."""


class HRSampler(object):
    """The abstract base class for hit-and-run samplers.

    Parameters
    ----------
    model : a cobra model
        The cobra model from which to generate samples.
    thinnning : int
        The thinning factor of the generated sampling chain. A thinning of 10
        means samples are returned every 10 steps.

    Attributes
    ----------
    model : a cobra model
        The cobra model from which the samples get generated.
    thinning : int
        The currently used thinning factor.
    n_samples : int
        The total number of samples that have been generated by this
        sampler instance.
    bounds : a numpy matrix
        The matrix has 2 rows, the first containing the lower flux bounds
        in its columns and the second the upper flux bounds.
    warmup : a numpy matrix
        A matrix of with as many columns as reactions in the model and more
        than 3 rows containing a warmup sample in each row. None if no warmup
        points have been generated yet.
    """

    def __init__(self, model, thinning):
        self.model = model
        self.thinning = thinning
        self.n_samples = 0
        self.bounds = np.array([[r.lower_bound, r.upper_bound]
                               for r in model.reactions]).T
        self.warmup = None

    def generate_fva_warmup(self, solver=None, **solver_args):
        """Generates the warmup points for the sampler.

        Generates warmup points by setting each flux as the sole objective
        and minimizing/maximizing it.

        Parameters
        ----------
        solver : str or cobra solver interface, optional
            The solver used for the arising LP problems.
        **solver_args
            Additional arguments passed to the solver.
        """

        solver = solver_dict[get_solver_name() if solver is None else solver]
        lp = solver.create_problem(self.model)
        for i, r in enumerate(self.model.reactions):
            solver.change_variable_objective(lp, i, 0.0)

        self.n_warmup = 2 * len(self.model.reactions)
        self.warmup = np.zeros((self.n_warmup, len(self.model.reactions)))

        idx = 0
        for sense in ("minimize", "maximize"):
            for i, r in enumerate(self.model.reactions):
                solver.change_variable_objective(lp, i, 1.0)
                solver.solve_problem(lp, objective_sense=sense, **solver_args)
                sol = solver.format_solution(lp, self.model).x
                # some solvers do not enforce bounds too much -> we recontrain
                sol = np.maximum(sol, self.bounds[0, ])
                sol = np.minimum(sol, self.bounds[1, ])
                self.warmup[idx, ] = sol
                idx += 1
                # revert objective
                solver.change_variable_objective(lp, i, 0.)

    def __step(self, x, delta):
        """Samples a feasible step from the point `x` in direction `delta`."""
        delta = delta / np.sqrt((delta * delta).sum())
        nonzero = np.abs(delta) > FTOL
        alphas = ((1.0 - BTOL) * self.bounds - x)[:, nonzero]
        alphas = (alphas / delta[nonzero]).flatten()
        alpha = np.random.uniform(alphas[alphas > 0].min(),
                                  alphas[alphas < 0].max())
        delta[np.logical_not(nonzero)] = 0.0
        return alpha * delta

    def sample(self):
        """Abstract sampling function.

        Should be overwritten by child classes.
        """
        pass

    def batch(self, batch_size, batch_num):
        """Generates a batch generator.

        This is useful to generate n batches of m samples each.

        Parameters
        ----------
        batch_size : int
            The number of samples contained in each batch (m).
        batch_num : int
            The number of batches in the generator (n).

        Yields
        ------
        numpy matrix
            A matrix containing with dimensions (batch_size x n_r) containing
            a valid flux sample for a total of n_r reactions in each row.
        """
        for i in range(batch_num):
            b = np.zeros((batch_size, len(self.model.reactions)))
            for j in range(batch_size):
                b[j, ] = self.sample()
            yield b

    def validate(self, samples):
        """Validates a set of samples for equality and inequality feasibility.

        Can be used to check whether the generated samples and warmup points
        are feasible.

        Parameters
        ----------
        samples : numpy matrix
            Must be of dimension (n_samples x n_reactions). Contains the
            samples to be validated.

        Returns
        -------
        numpy array
            A one-dimensional numpy array of length containing
            a boolean value for each sample which denotes whether the sample
            is feasible (True) or infeasible (False).
        """
        S = deepcopy(self.model).to_array_based_model().S
        feasibility = np.abs(S.dot(samples.T)).max(axis=0)
        lb_error = (samples - self.bounds[0, ]).min(axis=1)
        ub_error = (self.bounds[1, ] - samples).min(axis=1)

        valid = (feasibility < FTOL) & (lb_error > -BTOL) & (ub_error > -BTOL)
        return valid


class ARCHSampler(HRSampler):
    """Artificial Centering Hit-and-Run sampler.

    A sampler with low memory foot print and acceptable convergence.

    Parameters
    ----------
    model : a cobra model
        The cobra model from which to generate samples.
    thinnning : int, optional
        The thinning factor of the generated sampling chain. A thinning of 10
        means samples are returned every 10 steps.
    solver : str or cobra solver interface, optional
        The solver used for the arising LP problems during warmup point
        generation.
    **solver_args
        Additional arguments passed to the solver.

    Attributes
    ----------
    model : a cobra model
        The cobra model from which the samples get generated.
    thinning : int
        The currently used thinning factor.
    n_samples : int
        The total number of samples that have been generated by this
        sampler instance.
    bounds : a numpy matrix
        The matrix has 2 rows, the first containing the lower flux bounds
        in its columns and the second the upper flux bounds.
    warmup : a numpy matrix
        A matrix of with as many columns as reactions in the model and more
        than 3 rows containing a warmup sample in each row.
    prev : numpy array
        The cuurent/last flux sample generated.
    center : numpy array
        The center of the sampling space as estimated by the mean of all
        previously generated samples.

    Notes
    -----
    ARCH generates samples by choosing new directions from the sampling space's
    center and the warmup points. The implementation used here is the same
    as in the Matlab Cobra Toolbox and uses only the initial warmup points
    to generate new directions and not any other previous iterates. This
    usually gives better mixing since the startup points are chosen to span
    the space in a wide manner. This also makes the generated sampling chain
    quasi-markovian since the center converges rapidly.
    """

    def __init__(self, model, thinning=10, solver=None, **solver_kwargs):
        super(ARCHSampler, self).__init__(model)
        self.generate_fva_warmup(solver, **solver_kwargs)
        self.prev = self.center = self.warmup.mean(axis=0)

    def __single_iteration(self):
        pi = np.random.randint(self.n_warmup)
        # mix in the original warmup points to not get stuck
        p = self.warmup[pi, ]
        delta = p - self.center
        self.prev += self.__step(self.prev, delta)
        self.center = (self.n_samples * self.center + self.prev) / (
                       self.n_samples + 1)
        self.n_samples += 1

    def sample(self):
        for i in range(self.thinning):
            self.single_iteration()
        return self.prev
